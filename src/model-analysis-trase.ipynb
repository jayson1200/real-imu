{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-25T01:53:05.391644Z",
     "start_time": "2024-12-25T01:53:04.595365Z"
    }
   },
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from dataset import MotionDataset\n",
    "from time_model import TimeModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from trase import Trase\n",
    "\n",
    "data_path = \"/home/meribejayson/Desktop/Projects/realistic-imu/data/total_capture_data\"\n",
    "subjects = [\"s5\"]\n",
    "\n",
    "minimized_dataset = MotionDataset(data_path, subjects=subjects, dataset_type=\"minimized\", minimize=True)\n",
    "minimized_loader = DataLoader(minimized_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "orig_dataset = MotionDataset(data_path, subjects=subjects, dataset_type=\"orig\", minimize=False)\n",
    "orig_loader = DataLoader(orig_dataset, batch_size=1, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "acca1dcb3d5592b8",
   "metadata": {},
   "source": [
    "## Mean Squared Error of only applying a finite difference"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcd429de69f8f567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T01:53:05.414359Z",
     "start_time": "2024-12-25T01:53:05.404393Z"
    }
   },
   "source": [
    "num_exps = 0\n",
    "total = 0\n",
    "\n",
    "for mocap, imu in tqdm(orig_loader):\n",
    "    diff = imu[0, :, :] - mocap[0, :, 0:26:2]\n",
    "    sqr = diff ** 2\n",
    "\n",
    "    num_exps += sqr.shape[0] * sqr.shape[1]\n",
    "\n",
    "    total += torch.sum(sqr)\n",
    "\n",
    "total /= num_exps\n",
    "total.item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da27dea8ba0a41f884e078b3c666dee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12.683247566223145"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9fe844527083d78f",
   "metadata": {},
   "source": [
    "## Mean Squared Error with minimized accelerations"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ea521ccfb753f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T01:53:05.468514Z",
     "start_time": "2024-12-25T01:53:05.461903Z"
    }
   },
   "source": [
    "num_exps = 0\n",
    "total = 0\n",
    "\n",
    "for mocap, imu in tqdm(minimized_loader):\n",
    "    diff = imu[0, :, :] - mocap[0, :, 0:26:2]\n",
    "    sqr = diff ** 2\n",
    "\n",
    "    num_exps += sqr.shape[0] * sqr.shape[1]\n",
    "\n",
    "    total += torch.sum(sqr)\n",
    "\n",
    "total /= num_exps\n",
    "total.item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "658babf6e16e4c7e8459ab6ed04a57fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11.728960990905762"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "49042d45e144b509",
   "metadata": {},
   "source": [
    "## Mean Squared error with moving average"
   ]
  },
  {
   "cell_type": "code",
   "id": "74a38ef2b0208f5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T01:53:05.571865Z",
     "start_time": "2024-12-25T01:53:05.526147Z"
    }
   },
   "source": [
    "num_exps = 0\n",
    "total = 0\n",
    "\n",
    "for mocap, imu in tqdm(orig_loader):\n",
    "    avg_mocap = uniform_filter1d(mocap[0, :, 0:26:2].numpy(), size=11, mode='nearest', axis=0)\n",
    "    diff = imu[0, :, :] - avg_mocap\n",
    "    sqr = diff ** 2\n",
    "    num_exps += sqr.shape[0] * sqr.shape[1]\n",
    "\n",
    "    total += torch.sum(sqr)\n",
    "\n",
    "total /= num_exps\n",
    "total.item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33ae3b6a8fd7458ea11f72e034b1ad80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17.254222869873047"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b5ffaea4f8d0f5d3",
   "metadata": {},
   "source": [
    "## Mean Squared error with butterworth filter"
   ]
  },
  {
   "cell_type": "code",
   "id": "96cfb2e6bd5fb8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T01:53:05.598222Z",
     "start_time": "2024-12-25T01:53:05.583509Z"
    }
   },
   "source": [
    "def butterworth_filter(data, cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "cutoff = 10\n",
    "fs = 60\n",
    "order = 1\n",
    "\n",
    "num_exps = 0\n",
    "total = 0\n",
    "\n",
    "for mocap, imu in tqdm(orig_loader):\n",
    "    avg_mocap = butterworth_filter(mocap[0, :, 0:26:2].numpy(), cutoff, fs, order)\n",
    "    diff = imu[0, :, :] - avg_mocap\n",
    "    sqr = diff ** 2\n",
    "    num_exps += sqr.shape[0] * sqr.shape[1]\n",
    "\n",
    "    total += torch.sum(sqr)\n",
    "\n",
    "total /= num_exps\n",
    "total.item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b449d753a4a243179f9b9e7c391f8603"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11.479291288241145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "b7f8d29b5e9742ab",
   "metadata": {},
   "source": [
    "## Mean Squared Error of model output"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c55e2c2a7b11a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T01:58:25.623237Z",
     "start_time": "2024-12-25T01:58:25.602404Z"
    }
   },
   "source": [
    "model_path = '/home/meribejayson/Desktop/Projects/realistic-imu/src/weights/models-kind-gorge-29/best'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178567/2811321985.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Trase(\n",
       "  (linear1): Linear(in_features=42, out_features=512, bias=True)\n",
       "  (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (activation1): GELU(approximate='none')\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.5, inplace=False)\n",
       "          (dropout2): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (noise_regressor): Noise_Regressor(\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (hidden_state_to_noise_params): Linear(in_features=512, out_features=130, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "21f1cf6ea7ededbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T02:18:57.541304Z",
     "start_time": "2024-12-25T02:18:57.333509Z"
    }
   },
   "source": [
    "imus = []\n",
    "diffs = []\n",
    "num_exps = 0\n",
    "\n",
    "for mocap, imu in tqdm(minimized_loader):\n",
    "    avg_mocap, std = model(mocap.to(device), mocap[0, :, 0:26:2].T.to(device))\n",
    "    avg_mocap  = avg_mocap.cpu().detach().numpy()\n",
    "    std = std.cpu().detach().numpy()\n",
    "\n",
    "    diff = imu[0, :, :] - avg_mocap.T\n",
    "    diffs.append(diff)\n",
    "    imus.append(imu)\n",
    "\n",
    "    sqr = diff ** 2\n",
    "    num_exps += sqr.shape[0] * sqr.shape[1]\n",
    "\n",
    "    total += torch.sum(sqr)\n",
    "\n",
    "total /= num_exps\n",
    "total.item()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abd691fe08ec416c9ded4d5e4a220d93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9.59473394230343"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram_and_spectrum(diff):\n",
    "    # Filter data within the bounds\n",
    "    filtered_data = diff\n",
    "\n",
    "    # Compute mean, variance and nyquist frequency\n",
    "    mean_value = torch.mean(filtered_data)\n",
    "    variance_value = torch.var(filtered_data)\n",
    "    nyquist_frequency = 0.5 * len(filtered_data)\n",
    "\n",
    "    # Plot histogram density\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(filtered_data, bins=30, density=True, alpha=0.7, color='blue')\n",
    "    plt.title(f'Histogram Density\\nMean: {mean_value:.2f}, Variance: {variance_value:.2f}')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Density')\n",
    "\n",
    "    # Compute and plot power spectrum\n",
    "    plt.subplot(1, 2, 2)\n",
    "    freq = np.fft.rfftfreq(len(filtered_data))\n",
    "    power_spectrum = np.abs(np.fft.rfft(filtered_data)) ** 2\n",
    "    plt.plot(freq, np.log10(power_spectrum), color='red')\n",
    "    plt.title(f'Power Spectrum\\nNyquist Frequency: {nyquist_frequency:.2f}')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Power')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "ae79a3b81e9ec2d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate diffs and imu values from all trials and compute the plot\n",
    "diffs_for_plot = diffs[2][:, 0]\n",
    "\n",
    "plot_histogram_and_spectrum(diffs_for_plot)"
   ],
   "id": "2bc04cdc4ea467e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from hurst import compute_Hc\n",
    "\n",
    "# Calculate the Hurst exponent for diffs_for_plot\n",
    "H, c, data = compute_Hc(diffs_for_plot.numpy(), kind='random_walk', simplified=True)\n",
    "\n",
    "print(f\"Hurst Exponent: {H:.4f}\")\n",
    "print(f\"Scaling Coefficient: {c:.4f}\")"
   ],
   "id": "a8bcfaf5fd78e0c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98bedd12cea517a0",
   "metadata": {},
   "source": [
    "## Noise Bias Distribution over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "e65a7f440e444914",
   "metadata": {},
   "source": [
    "noise_bias_values = []\n",
    "\n",
    "NUM_OF_IMUS = 13\n",
    "NUM_OF_NOISE_PARAMS = 9\n",
    "\n",
    "def capture_noise_bias(module, input, output):\n",
    "    noise_params = module.hidden_state_to_noise_params(module.norm1(input[0])).view(-1, NUM_OF_NOISE_PARAMS, NUM_OF_IMUS)  # Reconstruct noise_params\n",
    "    noise_bias = noise_params[:, 8, :].T  # Extract noise_bias\n",
    "    noise_bias_values.append(noise_bias.detach().cpu())\n",
    "\n",
    "# Register the forward hook to `Noise_Regressor`\n",
    "hook = model.noise_regressor.register_forward_hook(capture_noise_bias)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mocap, imu in tqdm(minimized_loader):\n",
    "        avg_mocap = model(mocap.to(device), mocap[0, :, 0:26:2].T.to(device))\n",
    "\n",
    "hook.remove()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a627444df91de0",
   "metadata": {},
   "source": [
    "samples = torch.cat(noise_bias_values, dim=1).flatten().cpu().detach().numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abed87bf0331bfd7",
   "metadata": {},
   "source": [
    "## What is the unconditioned distribution of the noise bias and what distribution does it look the most like\n",
    "## Impossible to say without more analysis. With that said, the power spectral density is very pink, suggesting that 1/f noise or one of it higher orders might correctly describe the noise distribution\n",
    "## Additionally the histogram appears to be very log normal"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0c7b1fca159ea84",
   "metadata": {},
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts, bins, patches = plt.hist(samples, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Histogram')\n",
    "\n",
    "# Add KDE (Kernel Density Estimation) for smooth density estimation\n",
    "kde = gaussian_kde(samples)\n",
    "x_vals = np.linspace(min(samples), max(samples), 1000)\n",
    "kde_vals = kde(x_vals)\n",
    "plt.plot(x_vals, kde_vals, color='darkblue', lw=2, label='Density Estimate')\n",
    "\n",
    "# Add annotations (mean and median)\n",
    "mean = np.mean(samples)\n",
    "median = np.median(samples)\n",
    "plt.axvline(mean, color='red', linestyle='--', linewidth=1.5, label=f'Mean: {mean:.2f}')\n",
    "plt.axvline(median, color='green', linestyle='--', linewidth=1.5, label=f'Median: {median:.2f}')\n",
    "\n",
    "# Enhance plot aesthetics\n",
    "plt.title('Noise Bias Density', fontsize=16)\n",
    "plt.xlabel('Value', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../figures/noise_bias_density.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ea4abb46fc8a3e3",
   "metadata": {},
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "# Compute Power Spectral Density (PSD) using Welch's method\n",
    "fs = 60  # Sampling frequency in Hz\n",
    "frequencies, psd = welch(samples, fs=fs, nperseg=2048)  # nperseg should be <= len(samples)\n",
    "\n",
    "# Create the PSD plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(frequencies, psd, color='darkblue', lw=2)\n",
    "\n",
    "# Add labels, title, and grid for readability\n",
    "plt.title('Power Spectral Density (PSD)', fontsize=16)\n",
    "plt.xlabel('Frequency [Hz]', fontsize=14)\n",
    "plt.ylabel('Power Spectral Density [V**2/Hz]', fontsize=14)\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Highlight the Nyquist frequency\n",
    "nyquist = fs / 2\n",
    "plt.axvline(nyquist, color='red', linestyle='--', linewidth=1, label=f'Nyquist: {nyquist} Hz')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.savefig('../figures/psd.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Enhance plot aesthetics\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c2d43e6a95866b2",
   "metadata": {},
   "source": [
    "## Does anything occur when we start conditioning on the magnitude of the input embedding to the noise regressor\n",
    "\n",
    "## It appears that at smaller magnitudes the noise bias tends to vary more and seems to vary a lot as the magnitude of the embedding vector hits 50. After this point the variance decreases"
   ]
  },
  {
   "cell_type": "code",
   "id": "9edb5fa88e27e96a",
   "metadata": {},
   "source": [
    "noise_bias_values = []\n",
    "input_magnitudes = []\n",
    "\n",
    "NUM_OF_IMUS = 13\n",
    "NUM_OF_NOISE_PARAMS = 9\n",
    "\n",
    "def capture_noise_bias(module, input, output):\n",
    "    noise_params = module.hidden_state_to_noise_params(module.norm1(input[0])).view(-1, NUM_OF_NOISE_PARAMS, NUM_OF_IMUS)  # Reconstruct noise_params\n",
    "    noise_bias = noise_params[:, 8, :].T  # Extract noise_bias\n",
    "    noise_bias_values.append(torch.sum(noise_bias, dim=0).detach().cpu())\n",
    "\n",
    "# Register the forward hook to `Noise_Regressor`\n",
    "hook = model.noise_regressor.register_forward_hook(capture_noise_bias)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mocap, imu in tqdm(minimized_loader):\n",
    "        input_magnitudes.append(torch.norm(mocap, dim=2).squeeze(0).cpu())\n",
    "        avg_mocap = model(mocap.to(device), mocap[0, :, 0:26:2].T.to(device))\n",
    "\n",
    "\n",
    "hook.remove()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccc72b0cd5c44974",
   "metadata": {},
   "source": [
    "noise_bias_values[0].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c95f14b030d0a8db",
   "metadata": {},
   "source": [
    "input_magnitudes[0].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f88a3db55c953bde",
   "metadata": {},
   "source": [
    "noise = torch.cat(noise_bias_values, dim=0).flatten().cpu().detach().numpy()\n",
    "input_magnitudes = torch.cat(input_magnitudes, dim=0).flatten().cpu().detach().numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dca54ef780cc6865",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "noise_bias_samples = noise\n",
    "input_magnitudes = np.linspace(min(input_magnitudes), max(input_magnitudes), len(noise_bias_samples))\n",
    "\n",
    "bins = 35\n",
    "hist, x_edges, y_edges = np.histogram2d(input_magnitudes, noise_bias_samples, bins=bins, density=True)\n",
    "\n",
    "x_centers = (x_edges[1:] + x_edges[:-1]) / 2\n",
    "y_centers = (y_edges[1:] + y_edges[:-1]) / 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "heatmap = ax.imshow(hist.T, origin=\"lower\", cmap=\"viridis\",\n",
    "                    extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]],\n",
    "                    aspect=\"auto\")\n",
    "\n",
    "cbar = fig.colorbar(heatmap, ax=ax, shrink=0.8)\n",
    "cbar.set_label('Density', fontsize=12)\n",
    "\n",
    "ax.set_title('2D Heatmap of Noise Bias vs Input Magnitude', fontsize=16)\n",
    "ax.set_xlabel('Input Embedding Magnitude', fontsize=12)\n",
    "ax.set_ylabel('Noise Bias', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/bias-magnitude-heatmap.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93ea55f32446ca73",
   "metadata": {},
   "source": [
    "## Is there structure to the output embedding space\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5f27eec7c6781b4",
   "metadata": {},
   "source": [
    "output_emb = []\n",
    "\n",
    "NUM_OF_IMUS = 13\n",
    "NUM_OF_NOISE_PARAMS = 9\n",
    "\n",
    "def capture_noise_bias(module, input, output):\n",
    "    output_emb.append(output.detach().cpu())\n",
    "\n",
    "# Register the forward hook to `Noise_Regressor`\n",
    "hook = model.encoder.register_forward_hook(capture_noise_bias)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mocap, imu in tqdm(minimized_loader):\n",
    "        model(mocap.to(device), mocap[0, :, 0:26:2].T.to(device))\n",
    "\n",
    "\n",
    "hook.remove()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e154a3feeca6bda6",
   "metadata": {},
   "source": [
    "emb = torch.cat(output_emb, dim=1).cpu().squeeze(0).detach().numpy()\n",
    "emb.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34078efade32b05b",
   "metadata": {},
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "emb = StandardScaler().fit_transform(emb)\n",
    "\n",
    "# UMAP with adjusted parameters\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=50, min_dist=0.01, random_state=42)\n",
    "emb_2d = reducer.fit_transform(emb)\n",
    "\n",
    "# Clustering to identify clusters for coloring\n",
    "n_clusters = 3  # You can adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(emb_2d)\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Define cluster colors\n",
    "colors = sns.color_palette(\"tab10\", n_clusters)\n",
    "\n",
    "# Scatter plot with clusters\n",
    "for cluster in range(n_clusters):\n",
    "    plt.scatter(\n",
    "        emb_2d[labels == cluster, 0], emb_2d[labels == cluster, 1],\n",
    "        s=1, alpha=0.5, color=colors[cluster], label=f\"Cluster {cluster+1}\"\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"UMAP Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"UMAP Dimension 2\", fontsize=12)\n",
    "plt.title(\"UMAP Projection of Embedding Space with Clusters\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Remove spines for a cleaner look\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Add larger legend with colored patches\n",
    "legend_elements = [Patch(facecolor=colors[i], label=f\"Cluster {i+1}\") for i in range(n_clusters)]\n",
    "plt.legend(handles=legend_elements, fontsize=15, loc=\"upper right\", title=\"Clusters\", title_fontsize=15)\n",
    "\n",
    "cluster_1_mean = emb_2d[labels == 0].mean(axis=0)\n",
    "\n",
    "cluster_1_25_quantile = np.quantile(emb_2d[labels == 0], 0.25, axis=0)\n",
    "cluster_1_75_quantile = np.quantile(emb_2d[labels == 0], 0.75, axis=0)\n",
    "\n",
    "cluster_2_mean = emb_2d[labels == 1].mean(axis=0)\n",
    "\n",
    "cluster_2_25_quantile = np.quantile(emb_2d[labels == 1], 0.25, axis=0)\n",
    "cluster_2_75_quantile = np.quantile(emb_2d[labels == 1], 0.75, axis=0)\n",
    "\n",
    "cluster_3_mean = emb_2d[labels == 2].mean(axis=0)\n",
    "\n",
    "cluster_3_25_quantile = np.quantile(emb_2d[labels == 2], 0.25, axis=0)\n",
    "cluster_3_75_quantile = np.quantile(emb_2d[labels == 2], 0.75, axis=0)\n",
    "\n",
    "plt.scatter(cluster_1_mean[0], cluster_1_mean[1], color='red', marker='x', s=100, label=\"Cluster 1 Mean\")\n",
    "plt.scatter(cluster_1_25_quantile[0], cluster_1_25_quantile[1], color='red', marker='o', s=100, label=\"Cluster 1 25th Quantile\")\n",
    "plt.scatter(cluster_1_75_quantile[0], cluster_1_75_quantile[1], color='red', marker='s', s=100, label=\"Cluster 1 75th Quantile\")\n",
    "\n",
    "# Adding cluster 2 points\n",
    "plt.scatter(cluster_2_mean[0], cluster_2_mean[1], color='blue', marker='x', s=100, label=\"Cluster 2 Mean\")\n",
    "plt.scatter(cluster_2_25_quantile[0], cluster_2_25_quantile[1], color='blue', marker='o', s=100, label=\"Cluster 2 25th Quantile\")\n",
    "plt.scatter(cluster_2_75_quantile[0], cluster_2_75_quantile[1], color='blue', marker='s', s=100, label=\"Cluster 2 75th Quantile\")\n",
    "\n",
    "# Adding cluster 3 points\n",
    "plt.scatter(cluster_3_mean[0], cluster_3_mean[1], color='black', marker='x', s=100, label=\"Cluster 3 Mean\")\n",
    "plt.scatter(cluster_3_25_quantile[0], cluster_3_25_quantile[1], color='black', marker='o', s=100, label=\"Cluster 3 25th Quantile\")\n",
    "plt.scatter(cluster_3_75_quantile[0], cluster_3_75_quantile[1], color='black', marker='s', s=100, label=\"Cluster 3 75th Quantile\")\n",
    "\n",
    "# Update legend\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title for clarity\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Cluster Quantiles and Means\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/embedding_umap_projection.png\", dpi=900)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49561cbc6b9b706e",
   "metadata": {},
   "source": [
    "## What kind of outputs from the noise bias and the spring parameters usually output for say the imu on the foot for each cluster?"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f086994708742af",
   "metadata": {},
   "source": [
    "def find_nearest(target_point):\n",
    "    closest_idx = 0\n",
    "    for i in range(1, len(emb_2d)):\n",
    "        dist = np.linalg.norm(emb_2d[i] - target_point)\n",
    "        if dist < np.linalg.norm(emb_2d[closest_idx] - target_point):\n",
    "            closest_idx = i\n",
    "    return closest_idx"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e171882c030458f2",
   "metadata": {},
   "source": [
    "cluster_1_mean_point = emb[find_nearest(cluster_1_mean)]\n",
    "cluster_1_25_quantile = emb[find_nearest(cluster_1_25_quantile)]\n",
    "cluster_1_75_quantile = emb[find_nearest(cluster_1_75_quantile)]\n",
    "\n",
    "cluster_2_mean_point = emb[find_nearest(cluster_2_mean)]\n",
    "cluster_2_25_quantile = emb[find_nearest(cluster_2_25_quantile)]\n",
    "cluster_2_75_quantile = emb[find_nearest(cluster_2_75_quantile)]\n",
    "\n",
    "cluster_3_mean_point = emb[find_nearest(cluster_3_mean)]\n",
    "cluster_3_25_quantile = emb[find_nearest(cluster_3_25_quantile)]\n",
    "cluster_3_75_quantile = emb[find_nearest(cluster_3_75_quantile)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17a9f0e1f16e1b8e",
   "metadata": {},
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Noise_Series_Gen(nn.Module):\n",
    "    def __init__(self, d_model, device):\n",
    "        super(Noise_Series_Gen, self).__init__()\n",
    "\n",
    "        self.norm1 = model.noise_regressor.norm1 # nn.LayerNorm(d_model)\n",
    "        self.hidden_state_to_noise_params = model.noise_regressor.hidden_state_to_noise_params # nn.Linear(d_model, NUM_OF_IMUS * NUM_OF_NOISE_PARAMS)\n",
    "        self.eps = 1e-5\n",
    "        self.device = device\n",
    "\n",
    "    \"\"\"\n",
    "        hidden_states should be of dimension (Batch, Sequence Len, Dim)\n",
    "        B should always be 1\n",
    "    \"\"\"\n",
    "    # PLEASE CONVERT TO EINOPS (this will be hardly readable to anyone but the people who live in my head)\n",
    "    def forward(self, hidden_states):\n",
    "        seq_len = hidden_states.shape[1]\n",
    "\n",
    "        t_step = torch.triu(torch.arange(seq_len, device=self.device, dtype=torch.float32) - torch.arange(seq_len, device=self.device, dtype=torch.float32)[:, None])\n",
    "\n",
    "        hidden_normed = self.norm1(hidden_states)\n",
    "        noise_params = self.hidden_state_to_noise_params(hidden_normed).view(seq_len, NUM_OF_NOISE_PARAMS, NUM_OF_IMUS)\n",
    "\n",
    "        c = noise_params[:, 4, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        c_theta = noise_params[:, 5, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        phi = noise_params[:, 6, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        phi_theta = noise_params[:, 7, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        d = ((noise_params[:, 1, :] ** 2).add(self.eps)).sqrt_().view(seq_len, 1, NUM_OF_IMUS)\n",
    "        k = (d**2).div(4) + F.softplus(noise_params[:, 0, :]).view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        d_theta = ((noise_params[:, 3, :] ** 2).add_(self.eps)).sqrt_().view(seq_len, 1, NUM_OF_IMUS)\n",
    "        k_theta = (d_theta**2).div_(4) + F.softplus(noise_params[:, 2, :]).view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        noise_bias = noise_params[:, 8, :].T\n",
    "\n",
    "        dynamics_list = []\n",
    "        for imu_num in range(NUM_OF_IMUS):\n",
    "            k_imu = k[:, :, imu_num]\n",
    "            d_imu = d[:, :, imu_num]\n",
    "            omega1 = (k_imu.mul_(4) - (d_imu ** 2)).sqrt_() / 2\n",
    "\n",
    "            exp_term_linear = ((-d_imu / 2) * t_step).exp_()\n",
    "            sin_term_linear = (t_step * omega1).add_(phi[:, :, imu_num]).sin_()\n",
    "            linear_dynamics = c[:, :, imu_num] * exp_term_linear * sin_term_linear\n",
    "\n",
    "            k_theta_imu = k_theta[:, :, imu_num]\n",
    "            d_theta_imu = d_theta[:, :, imu_num]\n",
    "            omega1_theta = (k_theta_imu.mul_(4) - (d_theta_imu ** 2)).sqrt_() / 2\n",
    "\n",
    "            exp_term_angular = ((-d_theta_imu / 2) * t_step).exp_()\n",
    "            sin_term_angular = (t_step * omega1_theta).add_(phi_theta[:, :, imu_num]).sin_()\n",
    "            angular_dynamics = c_theta[:, :, imu_num] * exp_term_angular * sin_term_angular\n",
    "\n",
    "            spring_damper_dynamics_per_step = linear_dynamics.add_(angular_dynamics).triu_()\n",
    "\n",
    "            dynamics_list.append(spring_damper_dynamics_per_step[0, :].reshape(1, -1))\n",
    "\n",
    "\n",
    "        return torch.cat(dynamics_list, dim=0).add_(noise_bias)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ced9f3ecb1a61986",
   "metadata": {},
   "source": [
    "def get_series_from_emb(emb):\n",
    "    noise_series_gen = Noise_Series_Gen(d_model=512, device=device)\n",
    "\n",
    "    inp = torch.zeros((1, 120, 512)).to(device)\n",
    "    inp[0, 1, :] = torch.from_numpy(emb).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        series = noise_series_gen(inp)\n",
    "\n",
    "    return series.squeeze(0).cpu().numpy()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "969075d12317aaca",
   "metadata": {},
   "source": [
    "get_series_from_emb(cluster_1_mean_point)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cd0f8177c106cb4",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_time_series(series, title=\"Time Series Plot\", xlabel=\"Time\", ylabel=\"Value\", figsize=(12, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(series, label=\"Time Series\", color=\"blue\", linewidth=2)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.grid(alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df7dcdd7bd803fe4",
   "metadata": {},
   "source": [
    "plot_time_series(get_series_from_emb(cluster_3_mean_point)[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34cefd5f8e1d1e2",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = \"head\"\n",
    "\n",
    "def plot_cluster_time_series(\n",
    "    cluster_points,\n",
    "    quantiles,\n",
    "    labels,\n",
    "    figsize=(14, 14)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot all cluster points as stacked time series in a visually appealing way,\n",
    "    including quantiles (25th and 75th) for each cluster,\n",
    "    allowing variable scales for each plot.\n",
    "\n",
    "    Parameters:\n",
    "    cluster_points (list of arrays): List of time series arrays corresponding to cluster points.\n",
    "    quantiles (list of tuples): List of tuples where each tuple contains 25th and 75th quantile series arrays.\n",
    "    labels (list of str): Labels for each cluster.\n",
    "    title (str): Title of the plot.\n",
    "    figsize (tuple): Size of the figure.\n",
    "    \"\"\"\n",
    "    num_clusters = len(cluster_points)\n",
    "    fig, axes = plt.subplots(num_clusters * 3, 1, figsize=figsize, sharex=True, constrained_layout=True)\n",
    "\n",
    "    for i, (series, (q25, q75), label) in enumerate(zip(cluster_points, quantiles, labels)):\n",
    "        # Plot mean time series\n",
    "        axes[i * 3].plot(series, color='blue', lw=1.5, label=f\"{label} Mean\")\n",
    "        axes[i * 3].set_title(f\"{label} Mean\", fontsize=14)\n",
    "        axes[i * 3].grid(alpha=0.3, linestyle=\"--\")\n",
    "        axes[i * 3].set_ylabel(\"Value\", fontsize=12)\n",
    "        axes[i * 3].legend(fontsize=10)\n",
    "\n",
    "        # Plot 25th quantile\n",
    "        axes[i * 3 + 1].plot(q25, color='orange', lw=1.5, label=f\"{label} 25th Quantile\")\n",
    "        axes[i * 3 + 1].set_title(f\"{label} 25th Quantile\", fontsize=14)\n",
    "        axes[i * 3 + 1].grid(alpha=0.3, linestyle=\"--\")\n",
    "        axes[i * 3 + 1].set_ylabel(\"Value\", fontsize=12)\n",
    "        axes[i * 3 + 1].legend(fontsize=10)\n",
    "\n",
    "        # Plot 75th quantile\n",
    "        axes[i * 3 + 2].plot(q75, color='green', lw=1.5, label=f\"{label} 75th Quantile\")\n",
    "        axes[i * 3 + 2].set_title(f\"{label} 75th Quantile\", fontsize=14)\n",
    "        axes[i * 3 + 2].grid(alpha=0.3, linestyle=\"--\")\n",
    "        axes[i * 3 + 2].set_ylabel(\"Value\", fontsize=12)\n",
    "        axes[i * 3 + 2].legend(fontsize=10)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time\", fontsize=12)\n",
    "\n",
    "    plt.savefig(f'../figures/added-kinematics-{name}.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae91fd7fe35d7600",
   "metadata": {},
   "source": [
    "imu_idx = 0\n",
    "\n",
    "# Example usage with quantiles:\n",
    "cluster_points = [\n",
    "    get_series_from_emb(cluster_1_mean_point)[imu_idx],\n",
    "    get_series_from_emb(cluster_2_mean_point)[imu_idx],\n",
    "    get_series_from_emb(cluster_3_mean_point)[imu_idx]\n",
    "]\n",
    "quantiles = [\n",
    "    (get_series_from_emb(cluster_1_25_quantile)[imu_idx], get_series_from_emb(cluster_1_75_quantile)[imu_idx]),\n",
    "    (get_series_from_emb(cluster_2_25_quantile)[imu_idx], get_series_from_emb(cluster_2_75_quantile)[imu_idx]),\n",
    "    (get_series_from_emb(cluster_3_25_quantile)[imu_idx], get_series_from_emb(cluster_3_75_quantile)[imu_idx])\n",
    "]\n",
    "\n",
    "# Plot with updated functionality\n",
    "plot_cluster_time_series(cluster_points, quantiles,[\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imu_idx = -1\n",
    "\n",
    "name = \"left foot\"\n",
    "# Example usage with quantiles:\n",
    "cluster_points = [\n",
    "    get_series_from_emb(cluster_1_mean_point)[imu_idx],\n",
    "    get_series_from_emb(cluster_2_mean_point)[imu_idx],\n",
    "    get_series_from_emb(cluster_3_mean_point)[imu_idx]\n",
    "]\n",
    "quantiles = [\n",
    "    (get_series_from_emb(cluster_1_25_quantile)[imu_idx], get_series_from_emb(cluster_1_75_quantile)[imu_idx]),\n",
    "    (get_series_from_emb(cluster_2_25_quantile)[imu_idx], get_series_from_emb(cluster_2_75_quantile)[imu_idx]),\n",
    "    (get_series_from_emb(cluster_3_25_quantile)[imu_idx], get_series_from_emb(cluster_3_75_quantile)[imu_idx])\n",
    "]\n",
    "\n",
    "# Plot with updated functionality\n",
    "plot_cluster_time_series(cluster_points, quantiles,[\"Cluster 1\", \"Cluster 2\", \"Cluster 3\"])"
   ],
   "id": "2508e4f06580464f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9791260ae15de672",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "### Based on the limb the direction of the noise bias tend to stay together.\n",
    "### Some limbs, like the right foot essentially have no use of the spring kinematics, while others like the head do?\n",
    "### It appears that most of the time the oscillatory behavior is not decaying, rather it seem as though the model chooses arbitrary oscillatory behavior to fit itself to the imu data\n",
    "### It appears the model generally make more use of the noise bias than the spring dynamics\n",
    "### Given that the model is trying its absolute hardest to approximate some aribtitrary fourier series we might as well just allow it to do so and take the speed increase\n",
    "\n",
    "## More Questions\n",
    "### What is the mean and variance of the noise bias in each cluster\n",
    "### Find notable examples where the spring dynamics are used and are not.\n",
    "### What parts of the sequence matter most for these predictions? Is it simply just what is nearest? Or could different clusters require have verying attention maps. If it is clear that the model isn't using local information it means we could probably drop the transformer\n",
    "### I wonder how well this would do on synthesized data from nimble\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55e06b02c69aea",
   "metadata": {},
   "source": [
    "## What is the mean and variance of the noise bias in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "id": "635ce2abd701f91f",
   "metadata": {},
   "source": [
    "class Kinematic_Paramters(nn.Module):\n",
    "    def __init__(self, d_model, device):\n",
    "        super(Kinematic_Paramters, self).__init__()\n",
    "\n",
    "        self.norm1 = model.noise_regressor.norm1 # nn.LayerNorm(d_model)\n",
    "        self.hidden_state_to_noise_params = model.noise_regressor.hidden_state_to_noise_params # nn.Linear(d_model, NUM_OF_IMUS * NUM_OF_NOISE_PARAMS)\n",
    "        self.eps = 1e-5\n",
    "        self.device = device\n",
    "\n",
    "    \"\"\"\n",
    "        hidden_states should be of dimension (Batch, Sequence Len, Dim)\n",
    "        B should always be 1\n",
    "    \"\"\"\n",
    "    def forward(self, hidden_states):\n",
    "        seq_len = hidden_states.shape[1]\n",
    "\n",
    "        hidden_normed = self.norm1(hidden_states)\n",
    "        noise_params = self.hidden_state_to_noise_params(hidden_normed).view(seq_len, NUM_OF_NOISE_PARAMS, NUM_OF_IMUS)\n",
    "\n",
    "        c = noise_params[:, 4, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        c_theta = noise_params[:, 5, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        phi = noise_params[:, 6, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "        phi_theta = noise_params[:, 7, :].view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        d = ((noise_params[:, 1, :] ** 2).add(self.eps)).sqrt_().view(seq_len, 1, NUM_OF_IMUS)\n",
    "        k = (d**2).div(4) + F.softplus(noise_params[:, 0, :]).view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        d_theta = ((noise_params[:, 3, :] ** 2).add_(self.eps)).sqrt_().view(seq_len, 1, NUM_OF_IMUS)\n",
    "        k_theta = (d_theta**2).div_(4) + F.softplus(noise_params[:, 2, :]).view(seq_len, 1, NUM_OF_IMUS)\n",
    "\n",
    "        noise_bias = noise_params[:, 8, :].T\n",
    "\n",
    "        return (c, phi, d, k), (c_theta, phi_theta, d_theta, k_theta), noise_bias"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c90b1f1d26c6f79",
   "metadata": {},
   "source": [
    "emb_copy = torch.from_numpy(emb[np.newaxis, :, :]).to(device)\n",
    "\n",
    "kp = Kinematic_Paramters(d_model=512, device=device)\n",
    "\n",
    "linear, angular, noise_bias = kp(emb_copy)\n",
    "c, phi, d, k = linear\n",
    "c_theta, phi_theta, d_theta, k_theta = angular\n",
    "labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8270f641c2f6aee9",
   "metadata": {},
   "source": [
    "def plot_histograms(cluster_idx, target_imu):\n",
    "    filter = labels == cluster_idx\n",
    "    param_names = ['c', 'phi', 'd', 'k', 'c_theta', 'phi_theta', 'd_theta', 'k_theta', 'noise_bias']\n",
    "    param_values = [c[filter, 0, target_imu], phi[filter, 0, target_imu], d[filter, 0, target_imu], k[filter, 0, target_imu],\n",
    "                    c_theta[filter, 0, target_imu], phi_theta[filter, 0, target_imu], d_theta[filter, 0, target_imu], k_theta[filter, 0, target_imu],\n",
    "                    noise_bias[target_imu, filter]]\n",
    "\n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    for i, (name, values) in enumerate(zip(param_names, param_values), 1):\n",
    "        values_np = values.detach().cpu().numpy().flatten()\n",
    "        mean_val = values_np.mean()\n",
    "        var_val = values_np.var()\n",
    "\n",
    "        plt.subplot(3, 3, i)\n",
    "        plt.hist(values_np, bins=50, alpha=0.7, color='blue', edgecolor='black', density=True)  # Added `density=True`\n",
    "        plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        plt.axvline(mean_val + var_val**0.5, color='green', linestyle='--', label=f'+1 Std Dev')\n",
    "        plt.axvline(mean_val - var_val**0.5, color='green', linestyle='--', label=f'-1 Std Dev')\n",
    "        plt.title(f'Histogram of {name} for cluster {cluster_idx + 1}', fontsize=14)\n",
    "        plt.xlabel(f'{name}', fontsize=12)\n",
    "        plt.ylabel('Density', fontsize=12)  # Changed from 'Frequency' to 'Density'\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'../figures/param_dist-{cluster_idx}.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d41b70c8d67c8a54",
   "metadata": {},
   "source": [
    "plot_histograms(0, -4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fac6d84e4a071dad",
   "metadata": {},
   "source": [
    "plot_histograms(1, -4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b05e4f1f3e830276",
   "metadata": {},
   "source": [
    "plot_histograms(2, -4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "adee39a70b31407d",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "### Spring kinematics seem vary wildy based on what cluster the come from. Some from are obviously skewed while others have almost symmetric PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1bbd67e1a6521",
   "metadata": {},
   "source": [
    "## What matters most for predictions"
   ]
  },
  {
   "cell_type": "code",
   "id": "423a8d884e1aab88",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Custom TransformerEncoderLayer that always returns attention weights\n",
    "class MyTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask, is_causal=False):\n",
    "        # Override to always request attention weights\n",
    "        x, attn_weights = self.self_attn(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            key_padding_mask=key_padding_mask,\n",
    "            need_weights=True,\n",
    "            is_causal=is_causal\n",
    "        )\n",
    "        return self.dropout1(x), attn_weights\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
    "        x = src\n",
    "        if self.norm_first:\n",
    "            sa_out, attn_weights = self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)\n",
    "            x = x + sa_out\n",
    "            x = x + self._ff_block(self.norm2(x))\n",
    "        else:\n",
    "            sa_out, attn_weights = self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)\n",
    "            x = self.norm1(x + sa_out)\n",
    "            x = self.norm2(x + self._ff_block(x))\n",
    "        return x\n",
    "\n",
    "# Assuming your model is already loaded and stored in 'model'\n",
    "# For example: model = torch.load('my_loaded_model.pt') or similar.\n",
    "\n",
    "# Extract the original layers from the model\n",
    "original_layers = model._orig_mod.encoder.transformer_encoder.layers\n",
    "\n",
    "# Create a new ModuleList for the modified layers\n",
    "new_layers = nn.ModuleList()\n",
    "\n",
    "for old_layer in original_layers:\n",
    "    # Use GELU since original was using gelu, if needed\n",
    "    # If you know the original activation was gelu, this is safe\n",
    "    # Otherwise, detect from old_layer.activation_relu_or_gelu if possible\n",
    "    act_fn = F.gelu\n",
    "\n",
    "    new_layer = MyTransformerEncoderLayer(\n",
    "        d_model=old_layer.self_attn.embed_dim,\n",
    "        nhead=old_layer.self_attn.num_heads,\n",
    "        dim_feedforward=old_layer.linear1.weight.shape[0],\n",
    "        dropout=old_layer.dropout.p,\n",
    "        activation=act_fn,\n",
    "        layer_norm_eps=old_layer.norm1.eps,\n",
    "        batch_first=old_layer.self_attn.batch_first,\n",
    "        norm_first=old_layer.norm_first,\n",
    "        bias=True if old_layer.linear1.bias is not None else False\n",
    "    )\n",
    "\n",
    "    # Copy state_dict from old_layer to new_layer\n",
    "    new_layer.load_state_dict(old_layer.state_dict())\n",
    "    new_layers.append(new_layer)\n",
    "\n",
    "# Replace the old layers with the new ones in the model\n",
    "model._orig_mod.encoder.transformer_encoder.layers = new_layers\n",
    "\n",
    "class HookedEncoder(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(HookedEncoder, self).__init__()\n",
    "\n",
    "        self.attention_weights = []\n",
    "\n",
    "        # Reference the updated encoder components from model._orig_mod\n",
    "        self.encoder_layer = model._orig_mod.encoder.encoder_layer\n",
    "        self.transformer_encoder = model._orig_mod.encoder.transformer_encoder\n",
    "        self.norm1 = model._orig_mod.encoder.norm1\n",
    "        self.norm2 = model._orig_mod.encoder.norm2\n",
    "        self.feed_forward = model._orig_mod.encoder.feed_forward\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            # output is (attn_output, attn_weights)\n",
    "            # module is the MultiheadAttention\n",
    "            # We registered the hook on self_attn which returns (attn_output, attn_weights)\n",
    "            attn_weights = output[1]\n",
    "            self.attention_weights.append(attn_weights)\n",
    "\n",
    "        # Register hooks to capture attention weights\n",
    "        for layer in self.transformer_encoder.layers:\n",
    "            layer.self_attn.register_forward_hook(hook_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x_norm = self.norm1(x)\n",
    "        x_trans = self.transformer_encoder(x_norm)\n",
    "        x_norm_2 = self.norm2(x_trans)\n",
    "        ff_out = self.feed_forward(x_norm_2)\n",
    "        return ff_out + residual\n",
    "\n",
    "class Truncated_Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Truncated_Model, self).__init__()\n",
    "\n",
    "        # Reference initial layers from model._orig_mod\n",
    "        self.linear1 = model._orig_mod.linear1\n",
    "        self.layer_norm1 = model._orig_mod.layer_norm1\n",
    "        self.activation1 = model._orig_mod.activation1\n",
    "        self.encoder = HookedEncoder(model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.activation1(x)\n",
    "        encoded_states = self.encoder(x)\n",
    "        return encoded_states, self.encoder.attention_weights\n",
    "\n",
    "# Use your device, for example:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trunc_model = Truncated_Model(model).to(device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0ff2c8d92324cef",
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "trunc_model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_states, attn = trunc_model(torch.from_numpy(minimized_dataset.__getitem__(0)[0]).to(device))\n",
    "\n",
    "def visualize_attention_weights():\n",
    "    num_layers = len(attn)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15), dpi=300)\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < num_layers:\n",
    "            layer_attn = attn[idx].detach().cpu().numpy()[480:600, 480:600]\n",
    "            sns.heatmap(layer_attn, annot=False, cmap='magma', cbar=False, square=True, ax=ax)\n",
    "            ax.set_title(f'Layer {idx + 1}', fontsize=12)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        else:\n",
    "            ax.axis('off')  # Hide unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/attention-map.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25fba2f5e6fa4671",
   "metadata": {},
   "source": "visualize_attention_weights()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_colorbar_from_data(data, cmap='magma', label='Attention Weight'):\n",
    "    min_val = min(layer.min() for layer in data)\n",
    "    max_val = max(layer.max() for layer in data)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(2, 6), dpi=300)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_val, vmax=max_val))\n",
    "    cbar = fig.colorbar(sm, cax=ax)\n",
    "    cbar.set_label(label, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/color-bar-key.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "create_colorbar_from_data(attn, cmap='magma', label='Attention Weight')\n"
   ],
   "id": "acd64807c56f0487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Observations:\n",
    "\n",
    "## The attention maps are oddly not what you would expect. You would expect the attention maps to first be extremely local and gradually branch out.\n",
    "## However, what we observe is that in the earlier layers timesteps tend to attending to the same things. The attention weight only become more diverse in the later layers and not even really"
   ],
   "id": "6cb238e18b9fe230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "minimized_dataset.trial_order[2]",
   "id": "4960c4e8baf9038b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def stack_four_time_series(time, series1, series2, series3, series4,\n",
    "                           xlabel=None, title1=None, title2=None, title3=None, title4=None):\n",
    "    # Use a valid Matplotlib style (e.g., 'default' or 'classic')\n",
    "    plt.style.use('default')  # 'default' ensures broad compatibility across Matplotlib versions.\n",
    "    fig, axes = plt.subplots(4, 1, sharex=True, figsize=(8, 10), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "    # Determine the overall y-axis limits for consistency across all plots\n",
    "    ymin = min(series1.min(), series2.min(), series3.min(), series4.min())\n",
    "    ymax = max(series1.max(), series2.max(), series3.max(), series4.max())\n",
    "\n",
    "    # Plot the series with consistent y-axis limits\n",
    "    axes[0].plot(time, series1, color='blue', linewidth=1.5)\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].grid(True)\n",
    "    axes[0].set_ylim(ymin, ymax)\n",
    "\n",
    "    axes[1].plot(time, series2, color='green', linewidth=1.5)\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].set_ylim(ymin, ymax)\n",
    "\n",
    "    axes[2].plot(time, series3, color='red', linewidth=1.5)\n",
    "    axes[2].set_title(title3)\n",
    "    axes[2].grid(True)\n",
    "    axes[2].set_ylim(ymin, ymax)\n",
    "\n",
    "    axes[3].plot(time, series4, color='purple', linewidth=1.5)\n",
    "    axes[3].set_title(title4)\n",
    "    axes[3].set_xlabel(xlabel)\n",
    "    axes[3].grid(True)\n",
    "    axes[3].set_ylim(ymin, ymax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/time-series-graphs.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "model = None\n",
    "try:\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model: {e}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "series_mocap = minimized_dataset.__getitem__(2)[0]\n",
    "series_imu = minimized_dataset.__getitem__(2)[1]\n",
    "\n",
    "print(series_imu.shape)\n",
    "\n",
    "input_mocap = torch.from_numpy(series_mocap).to(device).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_imu = model(input_mocap, input_mocap[0, :, 0:26:2].T).detach().cpu().numpy()\n",
    "\n",
    "filtered = butterworth_filter(input_mocap[0, :, 0:26:2].detach().cpu().numpy(), cutoff, fs, order)\n",
    "\n",
    "time  = np.arange(series_mocap.shape[0])"
   ],
   "id": "527360e7f85a44c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pred_imu.shape",
   "id": "9186e27b6b511beb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the upper and lower bounds\n",
    "lower_bound = 3200\n",
    "upper_bound = lower_bound + 120\n",
    "imu_limb = -2\n",
    "\n",
    "# Create mask based on the bounds\n",
    "mask = (time >= lower_bound) & (time < upper_bound)\n",
    "\n",
    "# Select the specific column into separate variables\n",
    "imu_selected_data = series_imu[mask, imu_limb]\n",
    "mocap_selected_data = series_mocap[mask, imu_limb]\n",
    "pred_imu_selected_data = pred_imu.T[mask, imu_limb]\n",
    "filtered_selected_data = filtered[mask, imu_limb]\n",
    "\n",
    "# Pass the selected data to the plotting function\n",
    "stack_four_time_series(\n",
    "    time[mask], imu_selected_data, mocap_selected_data, pred_imu_selected_data, filtered_selected_data,\n",
    "    xlabel='Time',\n",
    "    title1='Original IMU Data ',\n",
    "    title2='Minimized Motion Capture',\n",
    "    title3='Predicted IMU Data',\n",
    "    title4='Butterworth Filtered'\n",
    ")\n",
    "\n",
    "# Calculate Mean Squared Errors\n",
    "mse_imu_vs_mocap = ((imu_selected_data - mocap_selected_data) ** 2).mean()\n",
    "mse_imu_vs_pred = ((imu_selected_data - pred_imu_selected_data) ** 2).mean()\n",
    "mse_imu_vs_filtered = ((imu_selected_data - filtered_selected_data) ** 2).mean()\n",
    "\n",
    "# Print the calculated MSEs\n",
    "print(f\"Mean Squared Error (IMU vs Mocap): {mse_imu_vs_mocap}\")\n",
    "print(f\"Mean Squared Error (IMU vs Predicted): {mse_imu_vs_pred}\")\n",
    "print(f\"Mean Squared Error (IMU vs Filtered): {mse_imu_vs_filtered}\")"
   ],
   "id": "cc1f36b6e15ded3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c1de0c8093290b96",
   "metadata": {},
   "source": [
    "## Stuff still left to do:\n",
    "### Compare your synthesized imu data to nimble's\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker-to-ang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
